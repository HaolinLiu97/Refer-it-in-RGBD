<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <meta name="google-site-verification" content="vIrKe6Ecwa3TVjmMt0OaJpDGw_SJa5IxzTA86wU44QE" />
</head>

<body>

<br/>
<br/>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:850px">
  
    <h2 align="center" id="title"><b>Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images</b></h2>
    <br/>
    <!-- <p align="center" id="title">Conference Name (NAME), YYYY.</p> -->

    <p align="center" class="center_text" id="authors">
        <a target="_blank">Haolin Liu</a><sup>1,2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">Anran Lin</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han</a><sup>1,2,*</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">Lei Yang</a><sup>4</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">Yizhou Yu</a><sup>3,4</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">Shuguang Cui</a><sup>1,2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
    </p>

    <p class="center_text" align="center">
        <sup>1</sup>Shenzhen Research Institute of Big Data, CUHK-Shenzhen
        &nbsp; &nbsp; &nbsp;
        <sup>2</sup>The Future Network of Intelligence Institue, CUHK-Shenzhen
        &nbsp; &nbsp; &nbsp;
        <sup>3</sup>Deepwise AI Lab
        &nbsp; &nbsp; &nbsp;
        <sup>4</sup>The University of Hong Kong
    </p>
    <p class="center_text" align="center">
        Corresponding Email: &nbsp; &nbsp; haolinliu@link.cuhk.edu.cn&nbsp; &nbsp; hanxiaoguang@cuhk.edu.cn
    </p>

    <br>
<!--         <h4 align="center" id="title"><b>Submit to our ScanRefer Localization Benchmark <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank">here</a>!</b></h4>

        <br><center><a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank"><img src="teaser.png" style="max-width:100%" /></a></center><br> -->

        
        <h3 class="w3-left-align" id="intro"><b>Introduction</b></h3>
        <p>
            We present a novel task of 3D visual grounding in <b>single-view RGB-D images</b> where the referred objects are often only <b>partially scanned</b>. 
            In contrast to previous works that directly generate object proposals for grounding in the 3D scenes, we propose a bottom-up approach to gradually aggregate information, effectively addressing the challenge posed by the partial scans. 
            Our approach first fuses the language and the visual features at the bottom level to generate a heatmap that coarsely localizes the relevant regions in the RGB-D image. Then our approach adopts an adaptive search based on the heatmap and performs the object-level matching with another visio-linguistic fusion to finally ground the referred object. 
            We evaluate the proposed method by comparing to the state-of-the-art methods on both the RGB-D images extracted from the ScanRefer dataset and our newly collected SUN-Refer dataset. Experiments show that our method outperforms the previous methods by a large margin (by 11.1% and 11.2%  Acc@0.5) on both datasets.
            <center>
                <img src="teaser.png" style="max-width:60%" /><br>
                <h7>
                Figure 1. We present a novel task of 3D visual grounding in single-view RGB-D images <br>given a referring expression, and propose a bottom-up neural approach to address it.<br> Predicted bounding boxes of the referred objects are in green.
                </h7>
            </center>
        </p>
        <h3 class="w3-left-align" id="video_title"><b>Introduction</b></h3>
        <p>
        <iframe width="850" height="480" src="https://www.youtube.com/watch?v=8elN2c2ewBE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </p>
        <h3 class="w3-left-align" id="dataset"><b>Dataset</b></h3>
        <a href="SUNREFER_dataset.json"> download SUNREFER dataset </a>
        <p>
        SUNREFER dataset is a large-scale dataset of referring expression dedicated for visual language research in RGBD images. It contains 38,480 annotations of referring expression on 7,699 RGBD images. Below is an example from SUNREFER dataset:
        </p>
        <center>
            <img src="dataset_example.png" style="max-width:60%" /><br>
            <h7>
                Figure 2. An example of the SUNREFER dataset with five different language descriptions referring to the chair enclosed by the green bounding box.
            </h7>
        </center>

        <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
        Accepted by CVPR 2021 <br>
        Paper - <a href="https://arxiv.org/pdf/2103.07894" target="__blank">ArXiv - pdf</a> (<a href="https://arxiv.org/abs/2103.07894" target="__blank">abs</a>)  | <a href="https://github.com/UncleMEDM/Refer-it-in-RGBD" target="__blank">GitHub</a>
        <br>
        If you find our work useful, please consider citing it:
        <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">

        
        @misc{liu2021referitinrgbd,
              title={Refer-it-in-RGBD: A Bottom-up Approach for 3D Visual Grounding in RGBD Images}, 
              author={Haolin Liu and Anran Lin and Xiaoguang Han and Lei Yang and Yizhou Yu and Shuguang Cui},
              year={2021},
              eprint={2103.07894},
              archivePrefix={arXiv},
              primaryClass={cs.CV}
        }
        </pre>

    </div>


</div>

<br/>
<br/>

</body>
</html>
